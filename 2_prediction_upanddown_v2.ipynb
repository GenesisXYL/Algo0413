{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM to predict next up and down\n",
    "## v2: Predict up and downs of the average of $\\mathbf{nforward}=10$ following prices\n",
    "\n",
    "1. Too slow to predict (next trade may happen in millisecond)\n",
    "2. Only classification of up, down and same. No quantitative prediction (can be improved to predict quantity of price movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/xunyingluo/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = 30\n",
    "n_epochs = 100\n",
    "time_steps = 50\n",
    "batch_size = 128\n",
    "activation = \"tanh\"\n",
    "loss = 'categorical_crossentropy'\n",
    "stop_patience=20\n",
    "\n",
    "dpi=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_dataset(x, y):\n",
    "    if x is not None:\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.reshape(x.shape[0], x.shape[1], 1)\n",
    "    if len(y.shape) == 1:\n",
    "        y = y.reshape(y.shape[0],1)\n",
    "    return x, y \n",
    "\n",
    "class LSTM_Model():\n",
    "    def __init__(self):\n",
    "        self.model = Sequential()\n",
    "        return \n",
    "    \n",
    "    def build(self,  time_steps = time_steps, data_dim = 1, output_dim = 3):\n",
    "        # expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "        # the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "        self.model.add(LSTM(hidden_dim, activation=activation, return_sequences=True, input_shape=(time_steps, data_dim)))\n",
    "        self.model.add(LSTM(hidden_dim, activation=activation, return_sequences=True))\n",
    "        self.model.add(LSTM(hidden_dim, activation=activation))\n",
    "        self.model.add(Dense(output_dim, activation = 'softmax'))\n",
    "        \n",
    "        opt=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "        self.model.compile(loss = loss, optimizer=opt, metrics=['accuracy']) \n",
    "        return self.model\n",
    "\n",
    "    def train_test(self, x, y, plot = False):\n",
    "        \n",
    "        size = len(x)\n",
    "        if size!=len(y):\n",
    "            return None\n",
    "        x = x[: batch_size * (size // batch_size)]\n",
    "        y = y[: batch_size * (size // batch_size)]\n",
    "        \n",
    "        x, y = reshape_dataset(x, y)\n",
    "\n",
    "        x_train, x_validation, y_train, y_validation= train_test_split(x, y, test_size = 0.1, shuffle = False)\n",
    "        print('train', x_train.shape, y_train.shape)\n",
    "        print('validation', x_validation.shape, y_validation.shape)\n",
    "       \n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=stop_patience, mode=\"min\", verbose=2, restore_best_weights=True)\n",
    "        history = self.model.fit(x_train, y_train, batch_size = batch_size, epochs = n_epochs,\n",
    "                                 validation_data=(x_validation, y_validation),callbacks=[early_stopping])\n",
    "        \n",
    "        self.y_pred = self.predict(x_validation)\n",
    "        self.y_validation_true = y_validation\n",
    "        \n",
    "        if plot == True:\n",
    "            self.train_plot = self.view_accuracy(self.predict(x_train).argmax(axis=1), y_train.argmax(axis=1), 'Train')\n",
    "            self.validation_plot = self.view_accuracy(self.predict(x_validation).argmax(axis=1), y_validation.argmax(axis=1), 'Validation')\n",
    "        return history\n",
    "\n",
    "    def predict(self, x_validation):\n",
    "        pred = self.model.predict(x_validation)\n",
    "        return pred\n",
    "    \n",
    "    def view_accuracy(self, y_pred = None, y_true = None, plot_name = 'Test', num=100):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.y_pred.argmax(axis=1)\n",
    "            y_true = self.y_validation_true.argmax(axis=1)\n",
    "        \n",
    "        plt.style.use('seaborn')\n",
    "        plt.figure(figsize = (20,6), dpi=dpi)\n",
    "        plt.grid(True)\n",
    "        plt.plot(y_pred[:num], color = 'lightcoral')\n",
    "        plt.plot(y_true[:num], color = 'cornflowerblue', linewidth = 1)\n",
    "        plt.title('{}_{}'.format(ticker, plot_name))\n",
    "        plt.legend(['predict', 'true'])\n",
    "#         if plot_name == 'Test':\n",
    "#             plt.savefig('{}_{}_{}_{}.png'.format(ticker, plot_name, str(time_steps), str(batch_size)))\n",
    "#         else:\n",
    "#             plt.savefig('{}_{}_{}_{}.png'.format(ticker, plot_name, str(time_steps), str(batch_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir=\"./data/\"\n",
    "ticker=\"TSLA\"\n",
    "\n",
    "date_pool=pd.date_range(\"1/1/2019\",\"1/31/2019\",freq=\"B\").strftime(\"%Y%m%d\")\n",
    "date_pool=[d for d in date_pool if os.path.exists(data_dir+\"trades_{}_{}.csv\".format(d,ticker))]\n",
    "\n",
    "train_days=10\n",
    "train_date_list=date_pool[:train_days]\n",
    "test_date_list=date_pool[train_days+1:]\n",
    "\n",
    "nforward=10\n",
    "\n",
    "def load_data(ticker, date):\n",
    "    df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(date, ticker),index_col=[0],parse_dates=[0])\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df[\"direction\"]=(df[\"trade_px\"]-df[\"trade_px\"].shift(1)).apply(np.sign)\n",
    "    df[\"pct_change\"]=df[\"trade_px\"].pct_change()\n",
    "    \n",
    "    mysign=lambda x: 0 if abs(x)<1e-5 else (1 if x>0 else -1)\n",
    "    df[\"label\"]=(df[\"trade_px\"].rolling(nforward).mean().shift(-nforward)-df[\"trade_px\"]).apply(mysign)\n",
    "    # df[\"label\"]=(df[\"trade_px\"].shift(-1)-df[\"trade_px\"]).apply(np.sign) # last version\n",
    "    \n",
    "    df.fillna(method=\"ffill\",inplace=True)\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    # print(df.head(10),df.shape)\n",
    "    # print(\"NaN number: \",df.isna().sum().sum())\n",
    "    \n",
    "    return df[[\"trade_px\",\"trade_size\",\"pct_change\",\"direction\",\"label\"]].values\n",
    "\n",
    "def create_dataset(ticker=ticker, dates=train_date_list, time_steps = time_steps, input_scaler=None):  \n",
    "\n",
    "    for i,d in enumerate(dates):\n",
    "        datanew = load_data(ticker,d)\n",
    "        if i==0:\n",
    "            data=datanew\n",
    "        else:\n",
    "            data=np.vstack((data, datanew))\n",
    "            \n",
    "    label=data[:,-1]\n",
    "    data=data[:,:-1]\n",
    "    \n",
    "    if input_scaler is None:\n",
    "        scaler=StandardScaler()\n",
    "        data=scaler.fit_transform(data)\n",
    "    else:\n",
    "        data=input_scaler.transform(data)\n",
    "        scaler=input_scaler\n",
    "\n",
    "    x = [data[0 : time_steps]]\n",
    "    y = [label[time_steps-1]]\n",
    "    N=len(data)//time_steps\n",
    "    \n",
    "    print(N)\n",
    "    for i in range(1, N):\n",
    "        t = data[i*time_steps: (i + 1)*time_steps]\n",
    "        x = np.vstack((x, [t]))\n",
    "        y.append(label[(i + 1)*time_steps-1])\n",
    "\n",
    "    y=pd.get_dummies(y)\n",
    "    #print(y)\n",
    "   \n",
    "    return x,y.values,scaler\n",
    "\n",
    "# x,y,_=create_dataset()\n",
    "# y.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_plot(history, plot_name = 'Loss'): # type(history) is dict\n",
    "    loss = np.asarray(history['loss'])\n",
    "    val_loss = np.asarray(history['val_loss'])\n",
    "    \n",
    "    plt.style.use('seaborn')\n",
    "    plt.figure(figsize = (20,6), dpi=dpi)\n",
    "    plt.grid(True)\n",
    "    plt.plot(loss, color = 'darkgrey')\n",
    "    plt.plot(val_loss, color = 'tan')\n",
    "    plt.legend(['loss', 'val_loss'])\n",
    "    # plt.savefig('{}_{}_{}_{}_{}.png'.format(ticker, plot_name, str(n_epochs), str(time_steps), str(batch_size)))\n",
    "\n",
    "def new_data_test(ticker, plot = True):\n",
    "    # Load train data\n",
    "    x, y, scaler = create_dataset(ticker)\n",
    "    print(\"Finished loading data.\")\n",
    "    \n",
    "    with open(\"model/LSTMv2_scaler_{}_{}.p\".format(train_date_list[0],train_date_list[-1]),\"wb\") as f:\n",
    "        pickle.dump(scaler,f)\n",
    "    \n",
    "    # Build model, in-sample train test\n",
    "    l = LSTM_Model()\n",
    "    l.build(time_steps = time_steps, data_dim = x.shape[-1], output_dim = y.shape[-1])\n",
    "    train_history = l.train_test(x, y, plot)  \n",
    "    if plot == True:\n",
    "        loss_plot(train_history.history)\n",
    "    \n",
    "    with open(\"model/LSTMv2_{}_{}.p\".format(train_date_list[0],train_date_list[-1]),\"wb\") as f:\n",
    "        pickle.dump(l,f)\n",
    "        \n",
    "    # Out-of-sample test\n",
    "    for test_date in test_date_list:\n",
    "        # create test dateset\n",
    "        x_test, y_test, _ = create_dataset(ticker=ticker, dates=[test_date], time_steps = time_steps, input_scaler=scaler)\n",
    "        x_test, y_test = reshape_dataset(x_test, y_test)\n",
    "    \n",
    "        # use precious trained model to test\n",
    "        y_test_pred = l.predict(x_test)\n",
    "        if plot == True:\n",
    "            l.view_accuracy(y_test_pred.argmax(axis=1), y_test.argmax(axis=1))\n",
    "        print(test_date+\" accuracy: \",np.mean(y_test_pred.argmax(axis=1)==y_test.argmax(axis=1)))\n",
    "    return l.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15154\n",
      "Finished loading data.\n",
      "train (13593, 50, 4) (13593, 3)\n",
      "validation (1511, 50, 4) (1511, 3)\n",
      "Train on 13593 samples, validate on 1511 samples\n",
      "Epoch 1/100\n",
      "13593/13593 [==============================] - 13s 949us/step - loss: 0.8623 - acc: 0.4819 - val_loss: 0.8465 - val_acc: 0.4924\n",
      "Epoch 2/100\n",
      "13593/13593 [==============================] - 12s 882us/step - loss: 0.8283 - acc: 0.5025 - val_loss: 0.8398 - val_acc: 0.5096\n",
      "Epoch 3/100\n",
      "13593/13593 [==============================] - 13s 925us/step - loss: 0.8025 - acc: 0.5390 - val_loss: 0.7956 - val_acc: 0.5711\n",
      "Epoch 4/100\n",
      "13593/13593 [==============================] - 11s 806us/step - loss: 0.7636 - acc: 0.5843 - val_loss: 0.7807 - val_acc: 0.5632\n",
      "Epoch 5/100\n",
      "13593/13593 [==============================] - 11s 795us/step - loss: 0.7529 - acc: 0.5867 - val_loss: 0.7796 - val_acc: 0.5586\n",
      "Epoch 6/100\n",
      "13593/13593 [==============================] - 11s 786us/step - loss: 0.7482 - acc: 0.5883 - val_loss: 0.7693 - val_acc: 0.5711\n",
      "Epoch 7/100\n",
      "13593/13593 [==============================] - 10s 771us/step - loss: 0.7431 - acc: 0.5899 - val_loss: 0.7726 - val_acc: 0.5665\n",
      "Epoch 8/100\n",
      "13593/13593 [==============================] - 11s 779us/step - loss: 0.7403 - acc: 0.5927 - val_loss: 0.7665 - val_acc: 0.5685\n",
      "Epoch 9/100\n",
      "13593/13593 [==============================] - 11s 794us/step - loss: 0.7378 - acc: 0.5935 - val_loss: 0.7654 - val_acc: 0.5678\n",
      "Epoch 10/100\n",
      "13593/13593 [==============================] - 11s 778us/step - loss: 0.7344 - acc: 0.5955 - val_loss: 0.7725 - val_acc: 0.5758\n",
      "Epoch 11/100\n",
      "13593/13593 [==============================] - 10s 759us/step - loss: 0.7324 - acc: 0.5956 - val_loss: 0.7626 - val_acc: 0.5692\n",
      "Epoch 12/100\n",
      "13593/13593 [==============================] - 11s 803us/step - loss: 0.7311 - acc: 0.5962 - val_loss: 0.7649 - val_acc: 0.5731\n",
      "Epoch 13/100\n",
      "13593/13593 [==============================] - 11s 821us/step - loss: 0.7297 - acc: 0.5977 - val_loss: 0.7633 - val_acc: 0.5771\n",
      "Epoch 14/100\n",
      "13593/13593 [==============================] - 11s 781us/step - loss: 0.7283 - acc: 0.5968 - val_loss: 0.7632 - val_acc: 0.5837\n",
      "Epoch 15/100\n",
      "13593/13593 [==============================] - 11s 826us/step - loss: 0.7267 - acc: 0.6030 - val_loss: 0.7627 - val_acc: 0.5639\n",
      "Epoch 16/100\n",
      "13593/13593 [==============================] - 12s 853us/step - loss: 0.7259 - acc: 0.5988 - val_loss: 0.7645 - val_acc: 0.5705\n",
      "Epoch 17/100\n",
      "13593/13593 [==============================] - 11s 814us/step - loss: 0.7247 - acc: 0.5960 - val_loss: 0.7729 - val_acc: 0.5632\n",
      "Epoch 18/100\n",
      "13593/13593 [==============================] - 11s 784us/step - loss: 0.7247 - acc: 0.5985 - val_loss: 0.7636 - val_acc: 0.5758\n",
      "Epoch 19/100\n",
      "13593/13593 [==============================] - 11s 785us/step - loss: 0.7226 - acc: 0.6018 - val_loss: 0.7654 - val_acc: 0.5692\n",
      "Epoch 20/100\n",
      "13593/13593 [==============================] - 11s 818us/step - loss: 0.7215 - acc: 0.6028 - val_loss: 0.7669 - val_acc: 0.5685\n",
      "Epoch 21/100\n",
      "13593/13593 [==============================] - 12s 862us/step - loss: 0.7211 - acc: 0.6027 - val_loss: 0.7659 - val_acc: 0.5731\n",
      "Epoch 22/100\n",
      "13593/13593 [==============================] - 11s 823us/step - loss: 0.7210 - acc: 0.6011 - val_loss: 0.7679 - val_acc: 0.5751\n",
      "Epoch 23/100\n",
      "13593/13593 [==============================] - 11s 808us/step - loss: 0.7206 - acc: 0.6036 - val_loss: 0.7661 - val_acc: 0.5599\n",
      "Epoch 24/100\n",
      "13593/13593 [==============================] - 11s 818us/step - loss: 0.7186 - acc: 0.6069 - val_loss: 0.7680 - val_acc: 0.5685\n",
      "Epoch 25/100\n",
      "13593/13593 [==============================] - 11s 819us/step - loss: 0.7182 - acc: 0.6085 - val_loss: 0.7670 - val_acc: 0.5652\n",
      "Epoch 26/100\n",
      "13593/13593 [==============================] - 11s 785us/step - loss: 0.7167 - acc: 0.6083 - val_loss: 0.7659 - val_acc: 0.5632\n",
      "Epoch 27/100\n",
      "13593/13593 [==============================] - 11s 815us/step - loss: 0.7152 - acc: 0.6097 - val_loss: 0.7660 - val_acc: 0.5804\n",
      "Epoch 28/100\n",
      "13593/13593 [==============================] - 11s 782us/step - loss: 0.7147 - acc: 0.6099 - val_loss: 0.7733 - val_acc: 0.5705\n",
      "Epoch 29/100\n",
      "13593/13593 [==============================] - 11s 783us/step - loss: 0.7138 - acc: 0.6094 - val_loss: 0.7685 - val_acc: 0.5625\n",
      "Epoch 30/100\n",
      "13593/13593 [==============================] - 11s 801us/step - loss: 0.7131 - acc: 0.6108 - val_loss: 0.7718 - val_acc: 0.5632\n",
      "Epoch 31/100\n",
      "13593/13593 [==============================] - 11s 806us/step - loss: 0.7115 - acc: 0.6131 - val_loss: 0.7712 - val_acc: 0.5711\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00031: early stopping\n",
      "808\n",
      "20190117 accuracy:  0.5903465346534653\n",
      "5342\n",
      "20190118 accuracy:  0.6089479595657057\n",
      "2570\n",
      "20190122 accuracy:  0.590272373540856\n",
      "2944\n",
      "20190123 accuracy:  0.6219429347826086\n",
      "1759\n",
      "20190124 accuracy:  0.5889710062535531\n",
      "1610\n",
      "20190125 accuracy:  0.5664596273291925\n",
      "1428\n",
      "20190128 accuracy:  0.5819327731092437\n",
      "1034\n",
      "20190129 accuracy:  0.6025145067698259\n",
      "2164\n",
      "20190130 accuracy:  0.5591497227356746\n",
      "2679\n",
      "20190131 accuracy:  0.5849197461739455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x139ab8400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_test(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 20190117 0.4707643580036127\n",
      "Accuracy of 20190118 0.43095347731518396\n",
      "Accuracy of 20190122 0.4555151005928208\n",
      "Accuracy of 20190123 0.45868338302510847\n",
      "Accuracy of 20190124 0.4674517203359969\n",
      "Accuracy of 20190125 0.463677230280151\n",
      "Accuracy of 20190128 0.48354217710885544\n",
      "Accuracy of 20190129 0.45997873779839565\n",
      "Accuracy of 20190130 0.45219857893910137\n",
      "Accuracy of 20190131 0.4725264061508603\n"
     ]
    }
   ],
   "source": [
    "# TICK FACTOR\n",
    "# only update if it's a trade\n",
    "# if message_type == 't':\n",
    "#     # calc the tick\n",
    "#     this_tick = np.sign(last_price - prev_price)\n",
    "#     if this_tick == 0:\n",
    "#         this_tick = prev_tick\n",
    "\n",
    "#     # now calc the tick\n",
    "#     if tick_factor == 0:\n",
    "#         tick_factor = this_tick\n",
    "#     else:\n",
    "#         tick_factor = (tick_ema_alpha * this_tick) + (1 - tick_ema_alpha) * tick_factor\n",
    "\n",
    "#         # store the last tick\n",
    "#     prev_tick = this_tick\n",
    "\n",
    "for test_date in test_date_list:\n",
    "    df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(test_date, ticker),index_col=[0],parse_dates=[0])\n",
    "    \n",
    "    df[\"tick_test\"]=(df[\"trade_px\"]-df[\"trade_px\"].shift(1)).apply(lambda x: 1 if x>0. else (-1. if x<0 else np.nan))\n",
    "    df.fillna(method=\"ffill\",inplace=True)\n",
    "    \n",
    "    df[\"tick_factor\"]=df[\"tick_test\"].ewm(span=20).mean()\n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    \n",
    "    mysign = lambda x: 0 if abs(x)<1e-5 else (1 if x>0 else -1)\n",
    "    df[\"predict\"]=df[\"tick_factor\"].apply(mysign)\n",
    "    df[\"real_movement\"]=(df[\"trade_px\"].rolling(nforward).mean().shift(-nforward)-df[\"trade_px\"]).apply(mysign)\n",
    "    \n",
    "    df.dropna(axis=0,inplace=True)\n",
    "    acc=np.mean(df[\"predict\"]==df[\"real_movement\"])\n",
    "    print(\"Accuracy of {}\".format(test_date),acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time interval between 10 trades is 0 days 00:00:02.094658\n"
     ]
    }
   ],
   "source": [
    "sum=pd.Timedelta(0)\n",
    "count=0\n",
    "for test_date in test_date_list:\n",
    "    df = pd.read_csv(data_dir+'trades_{}_{}.csv'.format(test_date, ticker),index_col=[0],parse_dates=[0])\n",
    "    timestamp=pd.DataFrame({\"trade_time\":df.index})\n",
    "    dt=timestamp[\"trade_time\"].shift(-nforward)-timestamp[\"trade_time\"]\n",
    "    dt.dropna(axis=0,inplace=True)\n",
    "    dt.apply(lambda x:x.seconds).hist()\n",
    "    sum+=dt.sum()\n",
    "    count+=dt.shape[0]\n",
    "print(\"Average time interval between {} trades is\".format(nforward),sum/count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
